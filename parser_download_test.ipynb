{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata file already exists! Delete them and continue\n",
      "GET request successful! Write in file\n",
      "reading file...\n",
      "Find old parsed data. Delete them!\n",
      "parsing html...\n",
      "parsing data...\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR INITIALIZE ENVIROMENT\n",
    "#from src.parser.parse import Parser\n",
    "#from src.parser.download import Downloader\n",
    "\n",
    "#p = Parser()\n",
    "#p.parse()\n",
    "#d = Downloader()\n",
    "#d.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 417ms/step - loss: 0.0463\n",
      "Epoch 2/5\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 418ms/step - loss: 0.0184\n",
      "Epoch 3/5\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 417ms/step - loss: 0.0152\n",
      "Epoch 4/5\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 417ms/step - loss: 0.0135\n",
      "Epoch 5/5\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 418ms/step - loss: 0.0129\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step\n",
      "[[ 1.0883601e+00  1.8224528e-03  1.6436216e-01 ... -1.3757643e+00\n",
      "  -3.4587455e+00  6.7716748e-01]\n",
      " [-1.8931849e+00  1.1005180e+00 -4.7166321e-01 ... -4.5085297e+00\n",
      "  -2.3456235e+00  1.8564640e+00]\n",
      " [-1.3530110e+00  2.8329725e+00 -5.6707263e-01 ...  9.4043803e-01\n",
      "   6.2297564e-04  1.1643528e+00]\n",
      " ...\n",
      " [-2.6827371e+00 -5.3432930e-01 -1.8340545e+00 ...  1.2892444e-01\n",
      "  -9.8754251e-03  3.5624781e+00]\n",
      " [-1.7354237e+00  2.1318052e+00 -6.5537113e-01 ...  6.7385054e-01\n",
      "  -1.6695842e+00  6.6912520e-01]\n",
      " [-4.3942010e-01 -2.5538042e+00  1.4140925e-01 ...  4.3326926e-01\n",
      "   8.9344543e-01  1.5963740e+00]]\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR FIT AUTOENCODER MODEL\n",
    "from src.autoencoder import Autoencoder\n",
    "\n",
    "e = Autoencoder()\n",
    "codes = e.fit_model()\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0883605e+00,  1.8225496e-03,  1.6435812e-01, -6.4314049e-01,\n",
       "        -2.0657356e+00, -3.9606071e+00,  1.3940756e+00,  2.9479015e-01,\n",
       "        -1.4115168e+00,  1.1939321e+00,  1.3921249e-01,  2.0073304e+00,\n",
       "        -5.8104765e-01, -7.3827058e-01, -4.3058687e-01, -2.8917871e+00,\n",
       "        -1.6183155e+00, -2.5692067e+00, -3.2810245e+00, -1.5354657e+00,\n",
       "         2.8588820e+00,  2.7202168e-01, -1.8353434e-01,  9.1589224e-01,\n",
       "         2.5736620e+00,  9.4432908e-01, -1.3921285e+00, -1.1727887e+00,\n",
       "         1.3623264e+00, -1.3757632e+00, -3.4587474e+00,  6.7716813e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from src.autoencoder import Autoencoder\n",
    "import pathlib\n",
    "\n",
    "a = Autoencoder()\n",
    "img = a.preprocess_image('./data/crops/0/crop_0.jpg')\n",
    "encoder = load_model('./src/models/encoder.keras')\n",
    "encoder.predict(img[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 146 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002542F3FF2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[7.37067938, 7.69900751, 7.78232288, 7.78457022, 7.94653034]]),\n",
       " array([[2077, 2653, 2256, 2551, 3910]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.find_image import Similar\n",
    "\n",
    "sim = Similar()\n",
    "sim.find_img('.\\\\data\\\\test_images\\\\crops\\\\test_1735202398.2086043\\\\crop_0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 78.9ms\n",
      "Speed: 0.0ms preprocess, 78.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "C:\\Users\\raven\\Projects\\hackathon_skillfactory\\data\\test_images\\crops\\test_1735202398.2086043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\raven\\\\Projects\\\\hackathon_skillfactory\\\\data\\\\test_images\\\\crops\\\\test_1735202398.2086043\\\\crop_1.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.yolo import process_image\n",
    "process_image('./data/test_images/auto/0.jpg', mode='search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30\n",
      "1 18\n",
      "2 36\n",
      "3 30\n",
      "4 30\n",
      "5 26\n",
      "6 36\n",
      "7 34\n",
      "8 32\n",
      "9 28\n",
      "10 34\n",
      "11 32\n",
      "12 26\n",
      "13 36\n",
      "14 28\n",
      "15 30\n",
      "16 30\n",
      "17 28\n",
      "18 22\n",
      "19 26\n",
      "20 30\n",
      "21 30\n",
      "22 28\n",
      "23 32\n",
      "24 26\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\raven\\\\Projects\\\\hackathon_skillfactory\\\\data\\\\images\\\\25.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1419\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     hash_true \u001b[38;5;241m=\u001b[39m imagehash\u001b[38;5;241m.\u001b[39mphash(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/images/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)   \n\u001b[0;32m      7\u001b[0m     hash_test \u001b[38;5;241m=\u001b[39m imagehash\u001b[38;5;241m.\u001b[39mphash(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/test_images/1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, hash_true\u001b[38;5;241m-\u001b[39mhash_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\raven\\\\Projects\\\\hackathon_skillfactory\\\\data\\\\images\\\\25.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "\n",
    "for i in range(1419):\n",
    "    hash_true = imagehash.phash(Image.open(f'./data/images/{i}.jpg'))   \n",
    "    hash_test = imagehash.phash(Image.open('./data/test_images/1.jpg'))\n",
    "    print(i, hash_true-hash_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg 4\n",
      "1.jpg 2\n",
      "10.jpg 3\n",
      "100.jpg 3\n",
      "1000.jpg 5\n",
      "1001.jpg 9\n",
      "1002.jpg 2\n",
      "1003.jpg 3\n",
      "1004.jpg 4\n",
      "1005.jpg 2\n",
      "1006.jpg 2\n",
      "1007.jpg 1\n",
      "1008.jpg 2\n",
      "1009.jpg 4\n",
      "101.jpg 2\n",
      "1010.jpg 3\n",
      "1011.jpg 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      5\u001b[0m     hash_true \u001b[38;5;241m=\u001b[39m imagehash\u001b[38;5;241m.\u001b[39mcrop_resistant_hash(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))   \n\u001b[1;32m----> 6\u001b[0m     hash_test \u001b[38;5;241m=\u001b[39m \u001b[43mimagehash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_resistant_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/test_images/1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file, hash_true\u001b[38;5;241m-\u001b[39mhash_test)\n\u001b[0;32m      8\u001b[0m     distance_arr\u001b[38;5;241m.\u001b[39mappend(hash_true\u001b[38;5;241m-\u001b[39mhash_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imagehash\\__init__.py:672\u001b[0m, in \u001b[0;36mcrop_resistant_hash\u001b[1;34m(image, hash_func, limit_segments, segment_threshold, min_segment_size, segmentation_image_size)\u001b[0m\n\u001b[0;32m    669\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mfilter(ImageFilter\u001b[38;5;241m.\u001b[39mGaussianBlur())\u001b[38;5;241m.\u001b[39mfilter(ImageFilter\u001b[38;5;241m.\u001b[39mMedianFilter())\n\u001b[0;32m    670\u001b[0m pixels \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(image)\u001b[38;5;241m.\u001b[39mastype(numpy\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 672\u001b[0m segments \u001b[38;5;241m=\u001b[39m \u001b[43m_find_all_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_segment_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# If there are no segments, have 1 segment including the whole image\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m segments:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imagehash\\__init__.py:626\u001b[0m, in \u001b[0;36m_find_all_segments\u001b[1;34m(pixels, segment_threshold, min_segment_size)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(already_segmented) \u001b[38;5;241m<\u001b[39m img_width \u001b[38;5;241m*\u001b[39m img_height:\n\u001b[0;32m    625\u001b[0m \tremaining_pixels \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mbitwise_and(threshold_pixels_i, unassigned_pixels)\n\u001b[1;32m--> 626\u001b[0m \tsegment \u001b[38;5;241m=\u001b[39m \u001b[43m_find_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malready_segmented\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \t\u001b[38;5;66;03m# Apply segment\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(segment) \u001b[38;5;241m>\u001b[39m min_segment_size:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imagehash\\__init__.py:581\u001b[0m, in \u001b[0;36m_find_region\u001b[1;34m(remaining_pixels, segmented_pixels)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_pixels[pixel]:\n\u001b[0;32m    580\u001b[0m \tin_region\u001b[38;5;241m.\u001b[39madd(pixel)\n\u001b[1;32m--> 581\u001b[0m \tnew_pixels\u001b[38;5;241m.\u001b[39madd(pixel)\n\u001b[0;32m    582\u001b[0m \tsegmented_pixels\u001b[38;5;241m.\u001b[39madd(pixel)\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "distance_arr = []\n",
    "for _, _, files in os.walk('./data/images'):\n",
    "    for file in files:\n",
    "        hash_true = imagehash.crop_resistant_hash(Image.open(f'./data/images/{file}'))   \n",
    "        hash_test = imagehash.crop_resistant_hash(Image.open('./data/test_images/1.jpg'))\n",
    "        print(file, hash_true-hash_test)\n",
    "        distance_arr.append(hash_true-hash_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 18, 34, 32, 28, 26, 26, 40, 32, 30, 36, 28, 32, 24, 32, 28, 28, 28, 36, 30, 34, 26, 34, 28, 38, 30, 40, 36, 26, 26, 38, 38, 32, 28, 24, 22, 34, 28, 30, 32, 32, 32, 22, 32, 28, 28, 36, 28, 20, 34, 28, 34, 34, 24, 36, 30, 32, 34, 36, 34, 30, 34, 34, 26, 32, 34, 36, 34, 30, 26, 26, 38, 30, 34, 28, 22, 28, 28, 36, 30, 30, 28, 36, 34, 26, 38, 30, 34, 34, 30, 36, 30, 34, 30, 32, 32, 30, 30, 32, 32, 34, 28, 32, 34, 28, 24, 34, 28, 32, 22, 30, 34, 30, 32, 26, 34, 32, 24, 30, 32, 36, 32, 30, 38, 32, 30, 34, 38, 28, 34, 30, 36, 32, 28, 30, 34, 34, 36, 32, 28, 32, 32, 22, 36, 30, 32, 32, 36, 36, 28, 34, 30, 38, 26, 38, 36, 34, 36, 34, 28, 30, 34, 32, 30, 30, 30, 34, 30, 34, 34, 16, 32, 32, 32, 32, 32, 32, 30, 28, 38, 26, 36, 26, 28, 28, 26, 22, 28, 28, 24, 32, 30, 26, 26, 34, 30, 36, 26, 32, 32, 34, 26, 28, 30, 28, 24, 32, 26, 30, 24, 28, 32, 34, 34, 34, 34, 34, 36, 28, 30, 32, 34, 30, 36, 26, 26, 38, 32, 34, 32, 28, 40, 30, 34, 34, 30, 38, 30, 28, 30, 28, 28, 26, 30, 26, 30, 28, 30, 32, 30, 26, 30, 34, 30, 34, 32, 32, 40, 30, 34, 26, 26, 30, 20, 28, 36, 38, 24, 30, 32, 28, 32, 32, 28, 28, 32, 32, 30, 34, 32, 24, 30, 30, 38, 32, 32, 30, 30, 32, 34, 40, 24, 34, 28, 36, 28, 28, 32, 34, 34, 30, 26, 26, 28, 22, 32, 28, 32, 26, 34, 30, 34, 36, 28, 32, 36, 32, 24, 28, 30, 32, 30, 28, 36, 28, 32, 28, 28, 44, 30, 32, 34, 28, 24, 30, 36, 30, 32, 34, 28, 32, 20, 18, 38, 30, 36, 30, 34, 34, 38, 22, 28, 28, 32, 24, 38, 26, 28, 28, 30, 30, 30, 30, 24, 30, 28, 16, 34, 32, 34, 30, 32, 30, 32, 28, 36, 32, 32, 26, 36, 36, 30, 22, 30, 38, 26, 32, 32, 36, 22, 32, 24, 28, 34, 30, 38, 28, 32, 30, 34, 28, 34, 36, 30, 32, 32, 34, 34, 34, 26, 26, 30, 32, 36, 30, 22, 26, 26, 42, 26, 30, 32, 32, 32, 32, 32, 28, 30, 34, 34, 34, 34, 38, 22, 30, 36, 28, 24, 34, 26, 26, 34, 36, 24, 26, 38, 28, 32, 24, 30, 34, 32, 36, 32, 32, 30, 32, 26, 28, 32, 32, 34, 34, 28, 36, 32, 30, 30, 28, 28, 34, 20, 26, 28, 28, 34, 30, 26, 28, 28, 32, 36, 30, 34, 26, 26, 22, 30, 26, 30, 30, 24, 32, 28, 30, 30, 32, 36, 28, 32, 30, 34, 36, 28, 38, 26, 32, 32, 30, 22, 28, 26, 32, 28, 30, 32, 30, 30, 34, 28, 26, 34, 36, 34, 24, 22, 32, 32, 32, 28, 32, 36, 30, 38, 32, 34, 36, 30, 36, 32, 24, 24, 28, 30, 36, 30, 30, 28, 34, 36, 28, 30, 28, 32, 28, 30, 30, 30, 30, 30, 30, 38, 36, 34, 36, 32, 24, 34, 26, 34, 40, 34, 24, 30, 42, 28, 26, 32, 28, 32, 32, 30, 24, 32, 32, 36, 32, 26, 30, 32, 30, 30, 32, 34, 34, 30, 32, 38, 26, 32, 30, 34, 32, 30, 26, 24, 28, 26, 26, 36, 36, 34, 26, 30, 24, 30, 28, 30, 32, 32, 30, 34, 34, 36, 22, 22, 32, 38, 30, 28, 30, 30, 28, 34, 38, 30, 26, 42, 30, 30, 18, 36, 30, 28, 28, 34, 36, 30, 30, 38, 32, 32, 36, 28, 26, 28, 34, 36, 32, 34, 28, 32, 30, 30, 26, 34, 36, 22, 36, 34, 32, 28, 40, 34, 20, 36, 32, 20, 30, 34, 32, 32, 30, 20, 22, 38, 32, 34, 32, 32, 28, 26, 24, 32, 30, 32, 26, 28, 36, 40, 28, 28, 30, 28, 32, 30, 40, 30, 36, 34, 34, 30, 34, 30, 28, 28, 34, 26, 34, 34, 30, 32, 28, 24, 28, 28, 34, 32, 26, 36, 22, 30, 30, 30, 28, 26, 28, 32, 26, 26, 42, 32, 24, 40, 30, 32, 32, 30, 26, 28, 30, 38, 24, 30, 20, 30, 20, 34, 30, 28, 28, 30, 30, 36, 26, 36, 38, 34, 26, 30, 28, 28, 28, 28, 30, 24, 26, 36, 40, 20, 32, 24, 34, 32, 38, 32, 30, 28, 30, 22, 22, 30, 34, 32, 18, 32, 34, 34, 32, 34, 34, 26, 26, 28, 34, 34, 18, 34, 32, 20, 30, 28, 34, 24, 36, 30, 38, 30, 34, 26, 32, 20, 30, 30, 20, 28, 36, 34, 28, 26, 30, 28, 36, 24, 30, 26, 30, 32, 26, 32, 34, 24, 24, 30, 28, 30, 28, 30, 32, 30, 30, 32, 28, 18, 32, 36, 34, 28, 36, 22, 26, 32, 32, 24, 26, 38, 28, 24, 38, 26, 36, 26, 32, 30, 28, 28, 32, 32, 36, 28, 28, 28, 32, 16, 26, 32, 26, 42, 34, 32, 30, 30, 28, 32, 30, 36, 32, 34, 38, 32, 32, 30, 30, 26, 38, 24, 30, 36, 36, 32, 34, 22, 30, 36, 36, 32, 30, 32, 26, 22, 28, 30, 28, 30, 28, 34, 28, 32, 30, 32, 30, 28, 26, 32, 32, 30, 30, 30, 28, 24, 26, 26, 40, 34, 34, 40, 30, 38, 36, 34, 32, 36, 46, 40, 38, 30, 34, 32, 38, 38, 26, 28, 30, 34, 22, 32, 28, 28, 28, 32, 32, 40, 28, 34, 32, 36, 36, 26, 30, 34, 28, 24, 34, 30, 28, 34, 26, 34, 34, 34, 28, 36, 30, 34, 30, 30, 30, 30, 26, 32, 30, 28, 28, 34, 32, 24, 34, 20, 26, 26, 32, 34, 30, 24, 34, 26, 30, 32, 32, 26, 32, 32, 32, 22, 34, 36, 26, 34, 34, 28, 26, 28, 32, 24, 30, 30, 34, 30, 28, 28, 30, 36, 28, 32, 32, 32, 28, 22, 28, 26, 38, 28, 30, 24, 32, 30, 34, 26, 26, 28, 28, 28, 26, 32, 30, 28, 26, 28, 28, 26, 36, 22, 34, 30, 24, 26, 32, 28, 26, 30, 30, 22, 38, 28, 26, 32, 34, 36, 40, 28, 32, 34, 24, 30, 34, 30, 32, 28, 28, 30, 26, 26, 28, 26, 26, 34, 26, 28, 34, 32, 30, 28, 30, 34, 32, 36, 30, 28, 26, 38, 24, 34, 32, 32, 30, 24, 34, 32, 26, 26, 28, 32, 30, 24, 32, 34, 36, 32, 30, 30, 24, 34, 24, 26, 34, 32, 24, 28, 36, 30, 38, 32, 34, 32, 28, 26, 32, 32, 36, 34, 34, 34, 24, 32, 36, 34, 34, 36, 30, 24, 28, 30, 28, 28, 30, 32, 28, 32, 26, 26, 32, 26, 28, 36, 26, 24, 32, 30, 22, 22, 38, 26, 34, 32, 26, 32, 30, 32, 34, 34, 30, 36, 28, 30, 36, 26, 28, 32, 32, 34, 30, 36, 30, 34, 32, 30, 32, 36, 26, 26, 32, 26, 32, 30, 36, 34, 28, 28, 20, 28, 22, 30, 28, 30, 34, 26, 30, 26, 38, 36, 38, 26, 32, 32, 28, 22, 30, 40, 26, 30, 32, 26, 30, 34, 26, 36, 36, 24, 28, 22, 28, 22, 26, 32, 32, 32, 38, 30, 22, 32, 34, 34, 26, 24, 22, 30, 36, 28, 30, 36, 30, 34, 32, 32, 28, 24, 28, 38, 34, 28, 32, 34, 28, 30, 30, 32, 30, 28, 30, 20, 34, 26, 38, 32, 30, 28, 34, 30, 28, 28, 32, 34, 30, 30, 26, 26, 34, 30, 28, 30, 28, 28, 26, 26, 24, 34, 28, 30, 30, 24, 24, 30, 30, 30, 32, 30, 24, 20, 18, 26, 34, 34, 34, 28, 34, 26, 32, 24, 26, 28, 30, 32, 30, 32, 36, 24, 40, 28, 42, 32, 26, 36, 34, 30, 26, 28, 30, 32, 24, 30, 32, 30, 22, 28, 22, 36, 24, 26, 36, 32, 28, 26, 34, 30, 28, 26, 34, 28, 32, 32, 32, 26, 32, 28, 28, 30, 30, 36, 38, 28, 30, 28, 28, 26, 32, 24, 30, 32, 32, 30, 28, 26, 28, 20, 26, 26, 28, 34, 28]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(str('./src/models/crop_map.pickle'), 'rb') as f:\n",
    "    crop_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# ADD CROP MAP FOR FIND IMAGE BY CROP\n",
    "#import pickle\n",
    "#import os\n",
    "#n = 0\n",
    "#crop_map = {}\n",
    "#for root, _, files in os.walk('./data/crops'):\n",
    "#    for file in files:\n",
    "#        crop_map.update({n: root.split('\\\\')[-1]})\n",
    "#        n+=1\n",
    "#with open(str('./src/models/crop_map.pickle'), 'wb') as f:\n",
    "#    pickle.dump(crop_map, f)       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
